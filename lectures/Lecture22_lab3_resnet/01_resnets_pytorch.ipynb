{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T17:47:38.092620Z",
     "iopub.status.busy": "2024-11-25T17:47:38.092292Z",
     "iopub.status.idle": "2024-11-25T17:47:38.096807Z",
     "shell.execute_reply": "2024-11-25T17:47:38.095693Z",
     "shell.execute_reply.started": "2024-11-25T17:47:38.092581Z"
    },
    "id": "ai72An86lqSS"
   },
   "outputs": [],
   "source": [
    "# do this step below to get lightning, lightning bolts, etc.\n",
    "# !pip install lightning-bolts torchvision torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kdonR3h-PEn"
   },
   "source": [
    "# Classification Revisited, with ResNets\n",
    "\n",
    "*AY 128/256 (UC Berkeley, 2018â€“2024)*\n",
    "\n",
    "Previously, we used CNNs in our own custom model to classify images. You are asked to stack up your own model to classify galaxies in Lab 3, and you should definitely explore different CNN depths, kernel sizes, and filters to get a feel for how this works. Many of them will be able to perform the functions you need for Lab 3 adequately. That said, some architectures are better than others, and an architecture we are going to introduce today, **ResNets (Residual neural Networks)** are particularly efficient at image classification.\n",
    "\n",
    "More generally, PyTorch comes with a bunch of models and pre-trained weights that come from fitting to some generic (in this case classification) data sets. As it turns out, many of the features in these trained CNNs are widely applicable and can be easily repurposed for another task. In this lecture, we will explore how to do that.\n",
    "\n",
    "Again, we'll make use of the Fashion MNIST labeled dataset, which you may recall looked something like this:\n",
    "\n",
    "<img src=\"https://github.com/zalandoresearch/fashion-mnist/blob/master/doc/img/fashion-mnist-sprite.png?raw=true\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJxs6AOJ-PEp"
   },
   "source": [
    "With labels: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:08:00.907687Z",
     "iopub.status.busy": "2024-11-25T18:08:00.906881Z",
     "iopub.status.idle": "2024-11-25T18:08:00.943640Z",
     "shell.execute_reply": "2024-11-25T18:08:00.940853Z",
     "shell.execute_reply.started": "2024-11-25T18:08:00.907584Z"
    },
    "id": "5B6atmbVWAa7"
   },
   "outputs": [],
   "source": [
    "lookup = {0: \"T-shirt/top\",\n",
    "          1: \"Trouser\",\n",
    "          2: \"Pullover\",\n",
    "          3: \"Dress\",\n",
    "          4: \"Coat\",\n",
    "          5: \"Sandal\",\n",
    "          6: \"Shirt\",\n",
    "          7: \"Sneaker\",\n",
    "          8: \"Bag\",\n",
    "          9: \"Ankle boot\"}\n",
    "\n",
    "def output_label(label):\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\n",
    "    return lookup[input]\n",
    "\n",
    "nb_classes = len(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:08:00.966564Z",
     "iopub.status.busy": "2024-11-25T18:08:00.966140Z",
     "iopub.status.idle": "2024-11-25T18:08:04.738413Z",
     "shell.execute_reply": "2024-11-25T18:08:04.737749Z",
     "shell.execute_reply.started": "2024-11-25T18:08:00.966527Z"
    },
    "id": "0o566vXl-PEq",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 2.3.0+cu121\n",
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import datetime, os\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import accuracy\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, ModelSummary\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# use a GPU or MPS (Mac) if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "\n",
    "print(\"pytorch version:\", torch.__version__)\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:08:04.739379Z",
     "iopub.status.busy": "2024-11-25T18:08:04.739118Z",
     "iopub.status.idle": "2024-11-25T18:08:08.958102Z",
     "shell.execute_reply": "2024-11-25T18:08:08.957454Z",
     "shell.execute_reply.started": "2024-11-25T18:08:04.739361Z"
    },
    "id": "uG5avg7hiTtx"
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"../Lecture20_lab3_pytorch/fashion-mnist_train.csv.gz\")\n",
    "test_csv = pd.read_csv(\"../Lecture20_lab3_pytorch/fashion-mnist_test.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:08:08.959013Z",
     "iopub.status.busy": "2024-11-25T18:08:08.958846Z",
     "iopub.status.idle": "2024-11-25T18:08:08.963497Z",
     "shell.execute_reply": "2024-11-25T18:08:08.962873Z",
     "shell.execute_reply.started": "2024-11-25T18:08:08.958997Z"
    },
    "id": "OOL83YFQiTty"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting fashion_dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile fashion_dataset.py\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, data, transform = None):\n",
    "        \"\"\"Method to initilaize variables.\"\"\" \n",
    "        self.fashion_MNIST = list(data.values)\n",
    "        self.transform = transform\n",
    "        \n",
    "        label = []\n",
    "        image = []\n",
    "        \n",
    "        for i in self.fashion_MNIST:\n",
    "             # first column is of labels.\n",
    "            label.append(i[0])\n",
    "            image.append(i[1:])\n",
    "        self.labels = np.asarray(label)\n",
    "        # Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\n",
    "        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:08:08.964303Z",
     "iopub.status.busy": "2024-11-25T18:08:08.964125Z",
     "iopub.status.idle": "2024-11-25T18:08:08.978274Z",
     "shell.execute_reply": "2024-11-25T18:08:08.977648Z",
     "shell.execute_reply.started": "2024-11-25T18:08:08.964286Z"
    }
   },
   "outputs": [],
   "source": [
    "from fashion_dataset import FashionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:08:08.980098Z",
     "iopub.status.busy": "2024-11-25T18:08:08.979933Z",
     "iopub.status.idle": "2024-11-25T18:08:09.360411Z",
     "shell.execute_reply": "2024-11-25T18:08:09.359761Z",
     "shell.execute_reply.started": "2024-11-25T18:08:08.980083Z"
    },
    "id": "OOL83YFQiTty"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "## Transform data into Tensor that has a range from 0 to 1\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.RandomAffine(degrees=15, shear=0.1),\n",
    "        #transforms.Resize(28),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Grayscale(3), \n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.RandomAffine(degrees=15, shear=0.1),\n",
    "        #transforms.Resize(28),\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "}\n",
    "\n",
    "train_set = FashionDataset(train_csv, transform=data_transforms['train'])\n",
    "test_set = FashionDataset(test_csv, transform=data_transforms['test'])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=2)\n",
    "test_loader = DataLoader(train_set, batch_size=batch_size, num_workers=2)\n",
    "\n",
    "train_label = torch.tensor([train_set[i][1] for i in range(nb_classes)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRlyeM7J-PE3"
   },
   "source": [
    "## Our (Previous) CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the model we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:08:09.361428Z",
     "iopub.status.busy": "2024-11-25T18:08:09.361157Z",
     "iopub.status.idle": "2024-11-25T18:08:09.373180Z",
     "shell.execute_reply": "2024-11-25T18:08:09.372487Z",
     "shell.execute_reply.started": "2024-11-25T18:08:09.361412Z"
    },
    "id": "Ftp5zXGFpi29"
   },
   "outputs": [],
   "source": [
    "class mycnn_dropout(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # define the layers here\n",
    "        # Conv2d(in_channels, out_channels, kernel_size)\n",
    "        # see https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "        self.layer1 = nn.Sequential(\n",
    "            #nn.Conv2d(1, 32, kernel_size=3),\n",
    "            nn.Conv2d(3, 32, kernel_size=3),\n",
    "            \n",
    "            # see https://github.com/sksq96/pytorch-summary/issues/55#issuecomment-471844028\n",
    "            # to understand why pytorch and keras differ here\n",
    "            nn.BatchNorm2d(32, affine=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(p=0.1)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fc1=torch.nn.Linear(1152, 32)\n",
    "        self.fc2=torch.nn.Linear(32, 10)\n",
    "    \n",
    "        self.loss = nn.NLLLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # add dropout \n",
    "        x = nn.Dropout(p=0.2)(x)\n",
    "\n",
    "        x=torch.relu(self.fc1(x))\n",
    "        x=F.log_softmax(self.fc2(x), dim=-1)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.75,\n",
    "            patience=2,\n",
    "            min_lr=1e-6,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_accuracy\"}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def _evaluate(self, batch, batch_idx, stage=None):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        acc = accuracy(preds, y, task=\"multiclass\", num_classes=nb_classes)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f'{stage}_loss', loss, prog_bar=True)\n",
    "            self.log(f'{stage}_accuracy', acc, prog_bar=True)\n",
    "\n",
    "        return loss, acc\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._evaluate(batch, batch_idx, 'val')[0]\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:08:09.375678Z",
     "iopub.status.busy": "2024-11-25T18:08:09.375494Z",
     "iopub.status.idle": "2024-11-25T18:08:10.067908Z",
     "shell.execute_reply": "2024-11-25T18:08:10.066971Z",
     "shell.execute_reply.started": "2024-11-25T18:08:09.375660Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "/home/aparsons/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/aparsons/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "  rank_zero_deprecation(\n",
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: nn_results/datalab_nn_pytorch_resnet_2024-11-25T18:02\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/home/aparsons/projects/pedagogy/ucb-datalab/course_materials_fall2024/lectures/Lecture22_lab3_resnet/nn_results/datalab_nn_pytorch_resnet_2024-11-25T18:02'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m     cpt \u001b[38;5;241m=\u001b[39m cpt[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReading from:\u001b[39m\u001b[38;5;124m'\u001b[39m, cpt)\n\u001b[0;32m---> 35\u001b[0m     model_dropout \u001b[38;5;241m=\u001b[39m \u001b[43mmycnn_dropout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcpt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     model_dropout \u001b[38;5;241m=\u001b[39m mycnn_dropout()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:139\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     67\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m     68\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:160\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     map_location \u001b[38;5;241m=\u001b[39m cast(_MAP_LOCATION_TYPE, \u001b[38;5;28;01mlambda\u001b[39;00m storage, loc: storage)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m--> 160\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[1;32m    163\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m _pl_migrate_checkpoint(\n\u001b[1;32m    164\u001b[0m     checkpoint, checkpoint_path\u001b[38;5;241m=\u001b[39m(checkpoint_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint_path, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:50\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload_state_dict_from_url(\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28mstr\u001b[39m(path_or_url),\n\u001b[1;32m     47\u001b[0m         map_location\u001b[38;5;241m=\u001b[39mmap_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(f, map_location\u001b[38;5;241m=\u001b[39mmap_location)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/spec.py:1298\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1297\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[0;32m-> 1298\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/implementations/local.py:191\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/implementations/local.py:355\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 355\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/implementations/local.py:360\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m--> 360\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n\u001b[1;32m    362\u001b[0m             compress \u001b[38;5;241m=\u001b[39m compr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression]\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/home/aparsons/projects/pedagogy/ucb-datalab/course_materials_fall2024/lectures/Lecture22_lab3_resnet/nn_results/datalab_nn_pytorch_resnet_2024-11-25T18:02'"
     ]
    }
   ],
   "source": [
    "run_time_string = datetime.datetime.utcnow().isoformat(timespec='minutes')\n",
    "filename = f'datalab_nn_pytorch_dropout_{run_time_string}'\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_accuracy',\n",
    "   min_delta=0.001,\n",
    "   patience=3,\n",
    "   verbose=True,\n",
    "   mode='max'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    dirpath='nn_results',\n",
    "    filename=filename,\n",
    "    verbose=True,\n",
    "    save_top_k=1\n",
    ")\n",
    "\n",
    "logger = [CSVLogger(\"nn_results1\", name=filename), TensorBoardLogger(\"nn_results1\", name=filename)]\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    myTrainer=pl.Trainer(callbacks=[early_stop_callback, checkpoint_callback], logger=logger,\n",
    "                     gpus=-1, accelerator='cuda', auto_select_gpus=True, max_epochs=5)\n",
    "else:\n",
    "    myTrainer=pl.Trainer(callbacks=[early_stop_callback, checkpoint_callback], logger=logger,\n",
    "                         max_epochs=5)\n",
    "if True:\n",
    "    cpt = !ls -td nn_results/*\n",
    "    cpt = cpt[0]\n",
    "    print('Reading from:', cpt)\n",
    "    model_dropout = mycnn_dropout.load_from_checkpoint(cpt).to(device)\n",
    "else:\n",
    "    model_dropout = mycnn_dropout().to(device)\n",
    "\n",
    "#summary(model_dropout.to(device), input_size=(1, 28, 28))\n",
    "summary(model_dropout, input_size=(3, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-25T18:08:10.068393Z",
     "iopub.status.idle": "2024-11-25T18:08:10.068642Z",
     "shell.execute_reply": "2024-11-25T18:08:10.068523Z",
     "shell.execute_reply.started": "2024-11-25T18:08:10.068512Z"
    },
    "id": "pTooZRBQqHZq"
   },
   "outputs": [],
   "source": [
    "#myTrainer.fit(model_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-25T18:08:10.069861Z",
     "iopub.status.idle": "2024-11-25T18:08:10.070209Z",
     "shell.execute_reply": "2024-11-25T18:08:10.070094Z",
     "shell.execute_reply.started": "2024-11-25T18:08:10.070082Z"
    },
    "id": "pTooZRBQqHZq"
   },
   "outputs": [],
   "source": [
    "model_dropout.eval()  # Set the model to evaluation mode\n",
    "# get a batch of data from the test set\n",
    "data = next(iter(test_loader))\n",
    "example_input = data[0].to(device)\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    predictions = model_dropout(example_input)\n",
    "\n",
    "# If you want the class with the highest probability\n",
    "predicted_class = torch.argmax(predictions, dim=1)\n",
    "\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNets\n",
    "ResNets are a neural net architecture designed for image classification tasks, but they have a long (for machine learning) history dating back to the 1980s.\n",
    "Generally, they are a solution to the problem that deep neural nets can \"lose track\" of image information in nets that aren't already well-trained. This makes it hard\n",
    "for gradients to be propagated deep into the network to identify useful features. The solution was to introduce \n",
    "skip connections (residual connections, or identity maps) between stacks of convolutional layers to allow gradients to flow directly through the network, mitigating the vanishing gradient problem in very deep networks.\n",
    "The residual blocks allow the model to learn identity mappings easily, making it more robust for deep architectures.\n",
    "\n",
    "<img src=\"ResBlock.png\" width=\"20%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Original-ResNet-18-Architecture.png\" width=\"50%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course, there are many flavors of residual networks with varying depths and numbers of parameters:\n",
    "\n",
    "<img src=\"resnet_param_counts.png\" width=\"50%\">\n",
    "\n",
    "This general architecture, whereby earlier layers are fed forward with intermediate layers providing augmented context, is also very widely used, including\n",
    "in U-Nets (used for image segmentation), Transformer networks (e.g. the \"T\" in GPT), and many others. But because we are interested in image classification,\n",
    "we'll start with ResNets here.\n",
    "\n",
    "Here's an example of some of the intermediate layers of a ResNet-18 that was trained on a very large and generic set of millions of labeled images, and is now being shown a hops berry (I think?).\n",
    "\n",
    "<img src=\"resnet_feature_visual.png\" width=\"50%\">\n",
    "\n",
    "What's interesting here is how generic the filter shapes are, especially in the first few layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous lecture, we examined how important it was to have large training sets, and to augment our training sets with transformations in order to avoid overfitting.\n",
    "Well, it turns out that training a ResNet on a huge number of images that have nothing to do with galaxies or fashion (or both?) can lead it to identify features\n",
    "that are generally usefull for image classification, and these features can help jump-start galaxy classification.\n",
    "\n",
    "Even better, someone else spend a huge amount of computing time getting you these weights, so you can leverage trainings that might have taken months on large GPU clusters to run.\n",
    "\n",
    "Harnessing pre-trained networks for new tasks is called **learning transfer**, and it can be quite powerful.\n",
    "The trick is, knowning where to create the splice between your pre-trained network and a custom network that focuses on your particular task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-25T18:08:10.070842Z",
     "iopub.status.idle": "2024-11-25T18:08:10.071081Z",
     "shell.execute_reply": "2024-11-25T18:08:10.070970Z",
     "shell.execute_reply.started": "2024-11-25T18:08:10.070959Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#class myresnet(pl.LightningModule):\n",
    "#    def __init__(self, num_classes=nb_classes):\n",
    "#        super(myresnet, self).__init__()\n",
    "#        \n",
    "#        self.model = models.resnet18(pretrained=True)\n",
    "#        # Freeze all layers initially (so their weights don't update)\n",
    "#        #for param in self.model.parameters():\n",
    "#        #    param.requires_grad = False\n",
    "#\n",
    "#        # Modify the final fully connected layer to match the number of classes\n",
    "#        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "#\n",
    "#        # Unfreeze specific layers (e.g., the final fully connected layer)\n",
    "#        #for param in self.model.fc.parameters():\n",
    "#        #    param.requires_grad = True\n",
    "#\n",
    "#        #self.loss = nn.CrossEntropyLoss()\n",
    "#        self.loss = nn.NLLLoss()\n",
    "#\n",
    "#\n",
    "#    def forward(self, x):\n",
    "#        x = self.model(x)\n",
    "#        #x = F.log_softmax(x, dim=-1)\n",
    "#        return x\n",
    "#\n",
    "#    def configure_optimizers(self):\n",
    "#        optimizer = torch.optim.Adam(self.parameters())\n",
    "#        \n",
    "#        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#            optimizer,\n",
    "#            mode='min',\n",
    "#            factor=0.75,\n",
    "#            patience=2,\n",
    "#            min_lr=1e-6,\n",
    "#            verbose=True\n",
    "#        )\n",
    "#        \n",
    "#        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_accuracy\"}\n",
    "#    \n",
    "#    def training_step(self, batch, batch_idx):\n",
    "#        x, y = batch\n",
    "#        logits = self.forward(x)\n",
    "#        loss = self.loss(logits, y)\n",
    "#        self.log('train_loss', loss)\n",
    "#        return loss\n",
    "#    \n",
    "#    def _evaluate(self, batch, batch_idx, stage=None):\n",
    "#        x, y = batch\n",
    "#        logits = self.forward(x)\n",
    "#        loss = self.loss(logits, y)\n",
    "#        preds = torch.argmax(logits, dim=-1)\n",
    "#        acc = accuracy(preds, y, task=\"multiclass\", num_classes=nb_classes)\n",
    "#\n",
    "#        if stage:\n",
    "#            self.log(f'{stage}_loss', loss, prog_bar=True)\n",
    "#            self.log(f'{stage}_accuracy', acc, prog_bar=True)\n",
    "#\n",
    "#        return loss, acc\n",
    "#    \n",
    "#    def validation_step(self, batch, batch_idx):\n",
    "#        return self._evaluate(batch, batch_idx, 'val')[0]\n",
    "#    \n",
    "#    def train_dataloader(self):\n",
    "#        return train_loader\n",
    "#    \n",
    "#    def val_dataloader(self):\n",
    "#        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-25T18:08:10.072175Z",
     "iopub.status.idle": "2024-11-25T18:08:10.072514Z",
     "shell.execute_reply": "2024-11-25T18:08:10.072396Z",
     "shell.execute_reply.started": "2024-11-25T18:08:10.072385Z"
    }
   },
   "outputs": [],
   "source": [
    "#run_time_string = datetime.datetime.utcnow().isoformat(timespec='minutes')\n",
    "#filename = f'datalab_nn_pytorch_resnet_{run_time_string}'\n",
    "#\n",
    "#early_stop_callback = EarlyStopping(\n",
    "#   monitor='val_accuracy',\n",
    "#   min_delta=0.001,\n",
    "#   patience=3,\n",
    "#   verbose=True,\n",
    "#   mode='max'\n",
    "#)\n",
    "#\n",
    "#checkpoint_callback = ModelCheckpoint(\n",
    "#    monitor='val_accuracy',\n",
    "#    mode='max',\n",
    "#    dirpath='nn_results',\n",
    "#    filename=filename,\n",
    "#    verbose=True,\n",
    "#    save_top_k=1\n",
    "#)\n",
    "#\n",
    "#logger = [CSVLogger(\"nn_results2\", name=filename), TensorBoardLogger(\"nn_results\", name=filename)]\n",
    "#\n",
    "#pl.seed_everything(42)\n",
    "#\n",
    "#if device == \"gpu\":\n",
    "#    myTrainer=pl.Trainer(callbacks=[early_stop_callback, checkpoint_callback], logger=logger,\n",
    "#                     gpus=-1, accelerator='dp', auto_select_gpus=True, max_epochs=5)\n",
    "#else:\n",
    "#    myTrainer=pl.Trainer(callbacks=[early_stop_callback, checkpoint_callback], logger=logger,\n",
    "#                         max_epochs=5)\n",
    "#    \n",
    "#model_resnet = myresnet().to(device)\n",
    "#summary(model_resnet, input_size=(3, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-25T18:08:10.073503Z",
     "iopub.status.idle": "2024-11-25T18:08:10.073925Z",
     "shell.execute_reply": "2024-11-25T18:08:10.073801Z",
     "shell.execute_reply.started": "2024-11-25T18:08:10.073790Z"
    }
   },
   "outputs": [],
   "source": [
    "#myTrainer.fit(model_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:08:30.580406Z",
     "iopub.status.busy": "2024-11-25T18:08:30.580076Z",
     "iopub.status.idle": "2024-11-25T18:08:30.594530Z",
     "shell.execute_reply": "2024-11-25T18:08:30.593912Z",
     "shell.execute_reply.started": "2024-11-25T18:08:30.580382Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, val_acc, \n",
    "                val_loss, train_acc, train_loss,epoch, \n",
    "                num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    list = {'train': {'acc': train_acc, 'loss': train_loss}, \n",
    "        'val':{'acc': val_acc, 'loss': val_loss}}\n",
    "    next = epoch\n",
    "    for epoch in range(next, next+num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, next + num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                #scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "        \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "        \n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "        \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "        \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()  # XXX\n",
    "        \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            list[phase]['loss'].append(epoch_loss)\n",
    "            list[phase]['acc'].append(epoch_acc.item())\n",
    "        \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "        \n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "        \n",
    "    return model, epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:08:11.648079Z",
     "iopub.status.busy": "2024-11-25T18:08:11.647106Z",
     "iopub.status.idle": "2024-11-25T18:08:11.892408Z",
     "shell.execute_reply": "2024-11-25T18:08:11.891608Z",
     "shell.execute_reply.started": "2024-11-25T18:08:11.648059Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aparsons/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/aparsons/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "model.fc = nn.Linear(model.fc.in_features, nb_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) # Decay LR by a factor of 0.1 every 7 epochs\n",
    "\n",
    "# load in previous save state, if available\n",
    "if False:\n",
    "    checkpoint = torch.load('./FMNIST_ResNet18_noresize.tar')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])  \n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    train_loss = checkpoint['train_loss']\n",
    "    train_acc = checkpoint['train_acc']\n",
    "    val_loss = checkpoint['val_loss']\n",
    "    val_acc = checkpoint['val_acc']\n",
    "    epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:08:14.794465Z",
     "iopub.status.busy": "2024-11-25T18:08:14.794226Z",
     "iopub.status.idle": "2024-11-25T18:08:14.797907Z",
     "shell.execute_reply": "2024-11-25T18:08:14.797338Z",
     "shell.execute_reply.started": "2024-11-25T18:08:14.794449Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "val_acc = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "dataloaders = {'train': train_loader, 'val': test_loader}\n",
    "dataset_sizes = {'train': len(train_loader.dataset.images), 'val': len(test_loader.dataset.images)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:08:35.871865Z",
     "iopub.status.busy": "2024-11-25T18:08:35.871583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aparsons/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "model, epoch = train_model(model, criterion, optimizer, scheduler, val_acc, val_loss,  train_acc, train_loss, epoch, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T17:59:19.968789Z",
     "iopub.status.busy": "2024-11-25T17:59:19.967857Z",
     "iopub.status.idle": "2024-11-25T17:59:20.203977Z",
     "shell.execute_reply": "2024-11-25T17:59:20.203240Z",
     "shell.execute_reply.started": "2024-11-25T17:59:19.968707Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save({'epoch' : epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss, 'val_loss': val_loss, \n",
    "            'train_acc': train_acc, 'val_acc': val_acc}, \n",
    "           './FMNIST_ResNet18_noresize.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "RDMy90B6-PEy",
    "IXWdI2td-PE5"
   ],
   "name": "02_CNNs-pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
