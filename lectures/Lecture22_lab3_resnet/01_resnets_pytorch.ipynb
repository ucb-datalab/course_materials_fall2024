{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ai72An86lqSS"
   },
   "outputs": [],
   "source": [
    "# do this step below to get lightning, lightning bolts, etc.\n",
    "# !pip install lightning-bolts torchvision torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kdonR3h-PEn"
   },
   "source": [
    "# Classification Revisited, with ResNets\n",
    "\n",
    "*AY 128/256 (UC Berkeley, 2018â€“2024)*\n",
    "\n",
    "Previously, we used CNNs in our own custom model to classify images. You are asked to stack up your own model to classify galaxies in Lab 3, and you should definitely explore different CNN depths, kernel sizes, and filters to get a feel for how this works. Many of them will be able to perform the functions you need for Lab 3 adequately. That said, some architectures are better than others, and an architecture we are going to introduce today, **ResNets (Residual neural Networks)** are particularly efficient at image classification.\n",
    "\n",
    "More generally, PyTorch comes with a bunch of models and pre-trained weights that come from fitting to some generic (in this case classification) data sets. As it turns out, many of the features in these trained CNNs are widely applicable and can be easily repurposed for another task. In this lecture, we will explore how to do that.\n",
    "\n",
    "Again, we'll make use of the Fashion MNIST labeled dataset, which you may recall looked something like this:\n",
    "\n",
    "<img src=\"https://github.com/zalandoresearch/fashion-mnist/blob/master/doc/img/fashion-mnist-sprite.png?raw=true\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJxs6AOJ-PEp"
   },
   "source": [
    "With labels: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T06:38:53.036537Z",
     "iopub.status.busy": "2024-11-25T06:38:53.036177Z",
     "iopub.status.idle": "2024-11-25T06:38:53.045048Z",
     "shell.execute_reply": "2024-11-25T06:38:53.044060Z",
     "shell.execute_reply.started": "2024-11-25T06:38:53.036506Z"
    },
    "id": "5B6atmbVWAa7"
   },
   "outputs": [],
   "source": [
    "def output_label(label):\n",
    "    output_mapping = {\n",
    "                 0: \"T-shirt/Top\",\n",
    "                 1: \"Trouser\",\n",
    "                 2: \"Pullover\",\n",
    "                 3: \"Dress\",\n",
    "                 4: \"Coat\", \n",
    "                 5: \"Sandal\", \n",
    "                 6: \"Shirt\",\n",
    "                 7: \"Sneaker\",\n",
    "                 8: \"Bag\",\n",
    "                 9: \"Ankle Boot\"\n",
    "                 }\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\n",
    "    return output_mapping[input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T06:46:45.470133Z",
     "iopub.status.busy": "2024-11-25T06:46:45.469857Z",
     "iopub.status.idle": "2024-11-25T06:46:45.478865Z",
     "shell.execute_reply": "2024-11-25T06:46:45.477768Z",
     "shell.execute_reply.started": "2024-11-25T06:46:45.470115Z"
    },
    "id": "0o566vXl-PEq",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 2.3.0+cu121\n",
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import datetime, os\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from IPython.external import mathjax\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import accuracy\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, ModelSummary\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# use a GPU or MPS (Mac) if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "\n",
    "print(\"pytorch version:\", torch.__version__)\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T06:38:58.797189Z",
     "iopub.status.busy": "2024-11-25T06:38:58.796461Z",
     "iopub.status.idle": "2024-11-25T06:39:02.952783Z",
     "shell.execute_reply": "2024-11-25T06:39:02.952197Z",
     "shell.execute_reply.started": "2024-11-25T06:38:58.797159Z"
    },
    "id": "uG5avg7hiTtx"
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"../Lecture20_lab3_pytorch/fashion-mnist_train.csv.gz\")\n",
    "test_csv = pd.read_csv(\"../Lecture20_lab3_pytorch/fashion-mnist_test.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T06:39:02.953830Z",
     "iopub.status.busy": "2024-11-25T06:39:02.953471Z",
     "iopub.status.idle": "2024-11-25T06:39:02.959829Z",
     "shell.execute_reply": "2024-11-25T06:39:02.958766Z",
     "shell.execute_reply.started": "2024-11-25T06:39:02.953785Z"
    },
    "id": "OOL83YFQiTty"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting fashion_dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile fashion_dataset.py\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, data, transform = None):\n",
    "        \"\"\"Method to initilaize variables.\"\"\" \n",
    "        self.fashion_MNIST = list(data.values)\n",
    "        self.transform = transform\n",
    "        \n",
    "        label = []\n",
    "        image = []\n",
    "        \n",
    "        for i in self.fashion_MNIST:\n",
    "             # first column is of labels.\n",
    "            label.append(i[0])\n",
    "            image.append(i[1:])\n",
    "        self.labels = np.asarray(label)\n",
    "        # Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\n",
    "        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T06:39:02.961423Z",
     "iopub.status.busy": "2024-11-25T06:39:02.961159Z",
     "iopub.status.idle": "2024-11-25T06:39:02.975441Z",
     "shell.execute_reply": "2024-11-25T06:39:02.974469Z",
     "shell.execute_reply.started": "2024-11-25T06:39:02.961404Z"
    }
   },
   "outputs": [],
   "source": [
    "from fashion_dataset import FashionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:31.044476Z",
     "iopub.status.busy": "2024-11-25T07:11:31.042959Z",
     "iopub.status.idle": "2024-11-25T07:11:31.364261Z",
     "shell.execute_reply": "2024-11-25T07:11:31.363578Z",
     "shell.execute_reply.started": "2024-11-25T07:11:31.044412Z"
    },
    "id": "OOL83YFQiTty"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "## Transform data into Tensor that has a range from 0 to 1\n",
    "#train_set = FashionDataset(train_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "#test_set = FashionDataset(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "#\n",
    "#train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=2, persistent_workers=True)\n",
    "#test_loader = DataLoader(train_set, batch_size=batch_size, num_workers=2, persistent_workers=True)\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.RandomAffine(degrees=15, shear=0.1),\n",
    "        #transforms.Resize(28),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Grayscale(3), \n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.RandomAffine(degrees=15, shear=0.1),\n",
    "        #transforms.Resize(28),\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "}\n",
    "\n",
    "#train_transforms = transforms.Compose([\n",
    "#        torchvision.transforms.ToPILImage(),\n",
    "#        torchvision.transforms.RandomAffine(degrees=15, shear=0.1),\n",
    "#        torchvision.transforms.RandomHorizontalFlip(),\n",
    "#        torchvision.transforms.ToTensor(),\n",
    "#])\n",
    "\n",
    "#train_set = FashionDataset(train_csv, transform=train_transforms)\n",
    "train_set = FashionDataset(train_csv, transform=data_transforms['train'])\n",
    "#test_set = FashionDataset(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = FashionDataset(test_csv, transform=data_transforms['test'])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=2)\n",
    "test_loader = DataLoader(train_set, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:32.608111Z",
     "iopub.status.busy": "2024-11-25T07:11:32.607205Z",
     "iopub.status.idle": "2024-11-25T07:11:32.630374Z",
     "shell.execute_reply": "2024-11-25T07:11:32.629296Z",
     "shell.execute_reply.started": "2024-11-25T07:11:32.608028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 9, 6, 0, 3, 4, 4, 5, 4, 8])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" \n",
    "    Converts a class vector (integers) to a binary class matrix.\n",
    "\n",
    "    Args:\n",
    "        y: A tensor of class indices (integers).\n",
    "        num_classes: The total number of classes.\n",
    "\n",
    "    Returns:\n",
    "        A binary matrix representation of the input.\n",
    "    \"\"\"\n",
    "    return torch.eye(num_classes)[y]\n",
    "\n",
    "nb_classes = 10\n",
    "train_label = torch.tensor([train_set[i][1] for i in range(10)])\n",
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:34.164973Z",
     "iopub.status.busy": "2024-11-25T07:11:34.163423Z",
     "iopub.status.idle": "2024-11-25T07:11:34.170413Z",
     "shell.execute_reply": "2024-11-25T07:11:34.169133Z",
     "shell.execute_reply.started": "2024-11-25T07:11:34.164900Z"
    }
   },
   "outputs": [],
   "source": [
    "#y_train = to_categorical(train_label, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRlyeM7J-PE3"
   },
   "source": [
    "## Our (Previous) CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:35.587417Z",
     "iopub.status.busy": "2024-11-25T07:11:35.586480Z",
     "iopub.status.idle": "2024-11-25T07:11:35.597261Z",
     "shell.execute_reply": "2024-11-25T07:11:35.594798Z",
     "shell.execute_reply.started": "2024-11-25T07:11:35.587333Z"
    },
    "id": "kHGC36yoiTt8"
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the model we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:36.904225Z",
     "iopub.status.busy": "2024-11-25T07:11:36.903352Z",
     "iopub.status.idle": "2024-11-25T07:11:36.913988Z",
     "shell.execute_reply": "2024-11-25T07:11:36.912258Z",
     "shell.execute_reply.started": "2024-11-25T07:11:36.904142Z"
    },
    "id": "ukdCwzPRiTt9"
   },
   "outputs": [],
   "source": [
    "#run_time_string = datetime.datetime.utcnow().isoformat(timespec='minutes')\n",
    "#filename = f'datalab_nn_pytorch_{run_time_string}'\n",
    "#\n",
    "#early_stop_callback = EarlyStopping(\n",
    "#   monitor='val_accuracy',\n",
    "#   min_delta=0.03,\n",
    "#   patience=3,\n",
    "#   verbose=True,\n",
    "#   mode='max'\n",
    "#)\n",
    "#\n",
    "#checkpoint_callback = ModelCheckpoint(\n",
    "#    monitor='val_accuracy',\n",
    "#    mode='max',\n",
    "#    dirpath='nn_results',\n",
    "#    filename=filename,\n",
    "#    verbose=True,\n",
    "#    save_top_k=1\n",
    "#)\n",
    "#\n",
    "#logger = [CSVLogger(\"nn_results1\", name=filename), TensorBoardLogger(\"nn_results\", name=filename)]\n",
    "#\n",
    "## reproducibility\n",
    "#pl.seed_everything(42)\n",
    "#\n",
    "#if device == \"gpu\":\n",
    "#    myTrainer=pl.Trainer(callbacks=[early_stop_callback, checkpoint_callback], logger=logger,\n",
    "#                                    gpus=-1, accelerator='auto', auto_select_gpus=True, max_epochs=5)\n",
    "#else:\n",
    "#    myTrainer=pl.Trainer(callbacks=[early_stop_callback, checkpoint_callback], logger=logger,\n",
    "#                                    accelerator='auto', max_epochs=5)\n",
    "#model=mycnn()\n",
    "#myTrainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:37.606750Z",
     "iopub.status.busy": "2024-11-25T07:11:37.606107Z",
     "iopub.status.idle": "2024-11-25T07:11:37.857213Z",
     "shell.execute_reply": "2024-11-25T07:11:37.856382Z",
     "shell.execute_reply.started": "2024-11-25T07:11:37.606692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 28, 28])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a batch of data from the test set\n",
    "data = next(iter(test_loader))\n",
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:38.435826Z",
     "iopub.status.busy": "2024-11-25T07:11:38.434724Z",
     "iopub.status.idle": "2024-11-25T07:11:38.444249Z",
     "shell.execute_reply": "2024-11-25T07:11:38.442623Z",
     "shell.execute_reply.started": "2024-11-25T07:11:38.435737Z"
    }
   },
   "outputs": [],
   "source": [
    "#cpt = !ls -t nn_results/*\n",
    "#cpt = cpt[0]\n",
    "#print(cpt)\n",
    "#\n",
    "## Load up the model class\n",
    "#model = mycnn.load_from_checkpoint(cpt).to(device)\n",
    "#model.eval()  # Set the model to evaluation mode\n",
    "#\n",
    "## Example input data, replace with your actual data\n",
    "#example_input = data[0].to(device)\n",
    "#\n",
    "## Get predictions\n",
    "#with torch.no_grad():  # Disable gradient calculation\n",
    "#    predictions = model(example_input)\n",
    "#\n",
    "## If you want the class with the highest probability\n",
    "#predicted_class = torch.argmax(predictions, dim=1)\n",
    "#\n",
    "#print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:39.255685Z",
     "iopub.status.busy": "2024-11-25T07:11:39.255296Z",
     "iopub.status.idle": "2024-11-25T07:11:39.261891Z",
     "shell.execute_reply": "2024-11-25T07:11:39.261196Z",
     "shell.execute_reply.started": "2024-11-25T07:11:39.255646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 9, 6, 0, 3, 4, 4, 5, 4, 8, 0, 8, 9, 0, 2, 2, 9, 3, 3, 3, 8, 7, 4, 4,\n",
       "        0, 4, 4, 8, 7, 1, 5, 0, 5, 3, 2, 7, 3, 4, 2, 1, 6, 0, 9, 6, 0, 5, 6, 7,\n",
       "        7, 2, 5, 2, 2, 4, 1, 4, 9, 8, 3, 4, 5, 5, 6, 3, 5, 8, 5, 9, 8, 1, 2, 8,\n",
       "        1, 3, 6, 8, 3, 4, 2, 5, 0, 2, 6, 8, 1, 2, 7, 6, 6, 4, 6, 5, 0, 1, 7, 3,\n",
       "        5, 8, 4, 3, 8, 5, 0, 5, 3, 0, 8, 5, 6, 1, 0, 7, 6, 1, 9, 7, 6, 9, 3, 3,\n",
       "        2, 6, 0, 6, 3, 6, 3, 5])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1] # these are the real labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:40.158195Z",
     "iopub.status.busy": "2024-11-25T07:11:40.157553Z",
     "iopub.status.idle": "2024-11-25T07:11:40.162158Z",
     "shell.execute_reply": "2024-11-25T07:11:40.161237Z",
     "shell.execute_reply.started": "2024-11-25T07:11:40.158164Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_set.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:40.823119Z",
     "iopub.status.busy": "2024-11-25T07:11:40.821172Z",
     "iopub.status.idle": "2024-11-25T07:11:40.830774Z",
     "shell.execute_reply": "2024-11-25T07:11:40.829152Z",
     "shell.execute_reply.started": "2024-11-25T07:11:40.823019Z"
    }
   },
   "outputs": [],
   "source": [
    "#all_test = torch.Tensor(test_set.images).reshape(-1, test_set.images.shape[3], \n",
    "#                                                 test_set.images.shape[1], \n",
    "#                                                 test_set.images.shape[2])\n",
    "#with torch.no_grad():  # Disable gradient calculation\n",
    "#    predictions = model(all_test.to(device))\n",
    "#predicted_class = torch.argmax(predictions, dim=1)\n",
    "#\n",
    "#conf_mat = confusion_matrix(test_set.labels, predicted_class.cpu())\n",
    "#\n",
    "#import seaborn as sns\n",
    "#sns.set_context(\"poster\")\n",
    "#conf_mat_normalized = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "#sns.heatmap(conf_mat_normalized)\n",
    "#plt.ylabel('True label')\n",
    "#plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:41.825038Z",
     "iopub.status.busy": "2024-11-25T07:11:41.823691Z",
     "iopub.status.idle": "2024-11-25T07:11:41.835824Z",
     "shell.execute_reply": "2024-11-25T07:11:41.832945Z",
     "shell.execute_reply.started": "2024-11-25T07:11:41.824910Z"
    }
   },
   "outputs": [],
   "source": [
    "#conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:43.603484Z",
     "iopub.status.busy": "2024-11-25T07:11:43.603119Z",
     "iopub.status.idle": "2024-11-25T07:11:43.607717Z",
     "shell.execute_reply": "2024-11-25T07:11:43.607000Z",
     "shell.execute_reply.started": "2024-11-25T07:11:43.603448Z"
    }
   },
   "outputs": [],
   "source": [
    "lookup = {0: \"T-shirt/top\",\n",
    "          1: \"Trouser\",\n",
    "          2: \"Pullover\",\n",
    "          3: \"Dress\",\n",
    "          4: \"Coat\",\n",
    "          5: \"Sandal\",\n",
    "          6: \"Shirt\",\n",
    "          7: \"Sneaker\",\n",
    "          8: \"Bag\",\n",
    "          9: \"Ankle boot\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:44.499512Z",
     "iopub.status.busy": "2024-11-25T07:11:44.499228Z",
     "iopub.status.idle": "2024-11-25T07:11:44.502725Z",
     "shell.execute_reply": "2024-11-25T07:11:44.502079Z",
     "shell.execute_reply.started": "2024-11-25T07:11:44.499490Z"
    }
   },
   "outputs": [],
   "source": [
    "#ind_wrong = []\n",
    "#for i, (pred, actual) in enumerate(zip(predicted_class.cpu(),test_set.labels)):\n",
    "#    if pred != actual:\n",
    "#        ind_wrong.append((i, pred.item(), actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:45.037511Z",
     "iopub.status.busy": "2024-11-25T07:11:45.036009Z",
     "iopub.status.idle": "2024-11-25T07:11:45.042509Z",
     "shell.execute_reply": "2024-11-25T07:11:45.041207Z",
     "shell.execute_reply.started": "2024-11-25T07:11:45.037462Z"
    }
   },
   "outputs": [],
   "source": [
    "#ind_wrong[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:45.487819Z",
     "iopub.status.busy": "2024-11-25T07:11:45.486288Z",
     "iopub.status.idle": "2024-11-25T07:11:45.493178Z",
     "shell.execute_reply": "2024-11-25T07:11:45.491652Z",
     "shell.execute_reply.started": "2024-11-25T07:11:45.487752Z"
    }
   },
   "outputs": [],
   "source": [
    "#ind = 10\n",
    "#plt.imshow(all_test[ind_wrong[ind][0]][0,:,:], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "#plt.axis(\"off\")\n",
    "#plt.title(f\"pred={lookup[ind_wrong[ind][1]]} true={lookup[ind_wrong[ind][2]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:11:46.038019Z",
     "iopub.status.busy": "2024-11-25T07:11:46.035803Z",
     "iopub.status.idle": "2024-11-25T07:11:46.047981Z",
     "shell.execute_reply": "2024-11-25T07:11:46.045680Z",
     "shell.execute_reply.started": "2024-11-25T07:11:46.037925Z"
    },
    "id": "WbxdGLblmeKe"
   },
   "outputs": [],
   "source": [
    "# XXX same as above\n",
    "#train_transforms = transforms.Compose([\n",
    "#        torchvision.transforms.ToPILImage(),\n",
    "#        torchvision.transforms.RandomAffine(degrees=15, shear=0.1),\n",
    "#        torchvision.transforms.RandomHorizontalFlip(),\n",
    "#        torchvision.transforms.ToTensor(),\n",
    "#])\n",
    "#\n",
    "#train_set = FashionDataset(train_csv, transform=train_transforms)\n",
    "#test_set = FashionDataset(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "#\n",
    "#train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=2)\n",
    "#test_loader = DataLoader(train_set, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:12:09.951749Z",
     "iopub.status.busy": "2024-11-25T07:12:09.950879Z",
     "iopub.status.idle": "2024-11-25T07:12:09.959534Z",
     "shell.execute_reply": "2024-11-25T07:12:09.957580Z",
     "shell.execute_reply.started": "2024-11-25T07:12:09.951650Z"
    },
    "id": "gNQ6SWYwmjqX"
   },
   "outputs": [],
   "source": [
    "#image, label = next(iter(train_set))\n",
    "#plt.axis('off')\n",
    "#\n",
    "#plt.imshow(image.squeeze(), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "#output_label(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:15:15.273682Z",
     "iopub.status.busy": "2024-11-25T07:15:15.273027Z",
     "iopub.status.idle": "2024-11-25T07:15:15.294477Z",
     "shell.execute_reply": "2024-11-25T07:15:15.293699Z",
     "shell.execute_reply.started": "2024-11-25T07:15:15.273607Z"
    },
    "id": "Ftp5zXGFpi29"
   },
   "outputs": [],
   "source": [
    "class mycnn_dropout(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # set this to an example input size to the see a summary\n",
    "        # see https://pytorch-lightning.readthedocs.io/en/latest/common/debugging.html\n",
    "        #self._example_input_array = torch.randn((1, 1, 28, 28))\n",
    "        self._example_input_array = torch.randn((1, 3, 28, 28))\n",
    "\n",
    "        # define the layers here\n",
    "        # Conv2d(in_channels, out_channels, kernel_size)\n",
    "        # see https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "        self.layer1 = nn.Sequential(\n",
    "            #nn.Conv2d(1, 32, kernel_size=3),\n",
    "            nn.Conv2d(3, 32, kernel_size=3),\n",
    "            \n",
    "            # see https://github.com/sksq96/pytorch-summary/issues/55#issuecomment-471844028\n",
    "            # to understand why pytorch and keras differ here\n",
    "            nn.BatchNorm2d(32, affine=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(p=0.1)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fc1=torch.nn.Linear(1152, 32)\n",
    "        self.fc2=torch.nn.Linear(32, 10)\n",
    "    \n",
    "        self.loss = nn.NLLLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # add dropout \n",
    "        x = nn.Dropout(p=0.2)(x)\n",
    "\n",
    "        x=torch.relu(self.fc1(x))\n",
    "        x=F.log_softmax(self.fc2(x), dim=-1)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.75,\n",
    "            patience=2,\n",
    "            min_lr=1e-6,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_accuracy\"}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def _evaluate(self, batch, batch_idx, stage=None):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        acc = accuracy(preds, y, task=\"multiclass\", num_classes=nb_classes)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f'{stage}_loss', loss, prog_bar=True)\n",
    "            self.log(f'{stage}_accuracy', acc, prog_bar=True)\n",
    "\n",
    "        return loss, acc\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._evaluate(batch, batch_idx, 'val')[0]\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:15:47.737283Z",
     "iopub.status.busy": "2024-11-25T07:15:47.736950Z",
     "iopub.status.idle": "2024-11-25T07:15:47.802626Z",
     "shell.execute_reply": "2024-11-25T07:15:47.801963Z",
     "shell.execute_reply.started": "2024-11-25T07:15:47.737251Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             896\n",
      "       BatchNorm2d-2           [-1, 32, 26, 26]               0\n",
      "              ReLU-3           [-1, 32, 26, 26]               0\n",
      "         MaxPool2d-4           [-1, 32, 13, 13]               0\n",
      "            Conv2d-5           [-1, 64, 11, 11]          18,496\n",
      "              ReLU-6           [-1, 64, 11, 11]               0\n",
      "         MaxPool2d-7             [-1, 64, 5, 5]               0\n",
      "           Dropout-8             [-1, 64, 5, 5]               0\n",
      "            Conv2d-9            [-1, 128, 3, 3]          73,856\n",
      "             ReLU-10            [-1, 128, 3, 3]               0\n",
      "           Linear-11                   [-1, 32]          36,896\n",
      "           Linear-12                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 130,474\n",
      "Trainable params: 130,474\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.70\n",
      "Params size (MB): 0.50\n",
      "Estimated Total Size (MB): 1.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_time_string = datetime.datetime.utcnow().isoformat(timespec='minutes')\n",
    "filename = f'datalab_nn_pytorch_dropout_{run_time_string}'\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_accuracy',\n",
    "   min_delta=0.001,\n",
    "   patience=3,\n",
    "   verbose=True,\n",
    "   mode='max'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    dirpath='nn_results',\n",
    "    filename=filename,\n",
    "    verbose=True,\n",
    "    save_top_k=1\n",
    ")\n",
    "\n",
    "logger = [CSVLogger(\"nn_results1\", name=filename), TensorBoardLogger(\"nn_results\", name=filename)]\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "#if device == \"gpu\":\n",
    "if True:\n",
    "    myTrainer=pl.Trainer(callbacks=[early_stop_callback, checkpoint_callback], logger=logger,\n",
    "                     gpus=-1, accelerator='cuda', auto_select_gpus=True, max_epochs=5)\n",
    "else:\n",
    "    myTrainer=pl.Trainer(callbacks=[early_stop_callback, checkpoint_callback], logger=logger,\n",
    "                         max_epochs=5)\n",
    "    \n",
    "model_dropout = mycnn_dropout()\n",
    "\n",
    "#summary(model_dropout.to(device), input_size=(1, 28, 28))\n",
    "summary(model_dropout.to(device), input_size=(3, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:15:54.238222Z",
     "iopub.status.busy": "2024-11-25T07:15:54.237750Z",
     "iopub.status.idle": "2024-11-25T07:18:18.448838Z",
     "shell.execute_reply": "2024-11-25T07:18:18.448236Z",
     "shell.execute_reply.started": "2024-11-25T07:15:54.238179Z"
    },
    "id": "pTooZRBQqHZq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | In sizes        | Out sizes      \n",
      "--------------------------------------------------------------------------\n",
      "0 | layer1 | Sequential | 896    | [1, 3, 28, 28]  | [1, 32, 13, 13]\n",
      "1 | layer2 | Sequential | 18.5 K | [1, 32, 13, 13] | [1, 64, 5, 5]  \n",
      "2 | layer3 | Sequential | 73.9 K | [1, 64, 5, 5]   | [1, 128, 3, 3] \n",
      "3 | fc1    | Linear     | 36.9 K | [1, 1152]       | [1, 32]        \n",
      "4 | fc2    | Linear     | 330    | [1, 32]         | [1, 10]        \n",
      "5 | loss   | NLLLoss    | 0      | ?               | ?              \n",
      "--------------------------------------------------------------------------\n",
      "130 K     Trainable params\n",
      "0         Non-trainable params\n",
      "130 K     Total params\n",
      "0.522     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aparsons/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843dde2c8d414b2d8f55baa8e3953e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_accuracy improved. New best score: 0.826\n",
      "Epoch 0, global step 469: 'val_accuracy' reached 0.82565 (best 0.82565), saving model to 'nn_results/datalab_nn_pytorch_dropout_2024-11-25T07:15.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_accuracy improved by 0.028 >= min_delta = 0.001. New best score: 0.854\n",
      "Epoch 1, global step 938: 'val_accuracy' reached 0.85385 (best 0.85385), saving model to 'nn_results/datalab_nn_pytorch_dropout_2024-11-25T07:15.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_accuracy improved by 0.013 >= min_delta = 0.001. New best score: 0.866\n",
      "Epoch 2, global step 1407: 'val_accuracy' reached 0.86637 (best 0.86637), saving model to 'nn_results/datalab_nn_pytorch_dropout_2024-11-25T07:15.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1876: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_accuracy improved by 0.015 >= min_delta = 0.001. New best score: 0.882\n",
      "Epoch 4, global step 2345: 'val_accuracy' reached 0.88173 (best 0.88173), saving model to 'nn_results/datalab_nn_pytorch_dropout_2024-11-25T07:15.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "myTrainer.fit(model_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNets\n",
    "Purpose: ResNet is primarily designed for image classification tasks.\n",
    "Architecture: ResNet uses a series of convolutional layers with residual connections (skip connections) to allow gradients to flow directly through the network, mitigating the vanishing gradient problem in very deep networks.\n",
    "Output: Produces a single label or a vector of class probabilities for an input image.\n",
    "Key Feature: The residual blocks allow the model to learn identity mappings easily, making it more robust for deep architectures.\n",
    "Input/Output Size:\n",
    "\n",
    "    Input: Fixed-size image (e.g., 224x224 for ResNet-50).\n",
    "    Output: A vector representing class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:19:06.822004Z",
     "iopub.status.busy": "2024-11-25T07:19:06.821632Z",
     "iopub.status.idle": "2024-11-25T07:19:06.834499Z",
     "shell.execute_reply": "2024-11-25T07:19:06.833829Z",
     "shell.execute_reply.started": "2024-11-25T07:19:06.821979Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import models, transforms\n",
    "\n",
    "class myresnet(pl.LightningModule):\n",
    "    def __init__(self, num_classes=nb_classes):\n",
    "        super(myresnet, self).__init__()\n",
    "        \n",
    "        # set this to an example input size to the see a summary\n",
    "        # see https://pytorch-lightning.readthedocs.io/en/latest/common/debugging.html\n",
    "        self._example_input_array = torch.randn((1, 3, 28, 28))\n",
    "        \n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        # Freeze all layers initially (so their weights don't update)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Modify the final fully connected layer to match the number of classes\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "        # Unfreeze specific layers (e.g., the final fully connected layer)\n",
    "        #for param in self.model.fc.parameters():\n",
    "        #    param.requires_grad = True\n",
    "\n",
    "        #self.loss = nn.CrossEntropyLoss()\n",
    "        self.loss = nn.NLLLoss()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        #x = F.log_softmax(x, dim=-1)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.75,\n",
    "            patience=2,\n",
    "            min_lr=1e-6,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_accuracy\"}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def _evaluate(self, batch, batch_idx, stage=None):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        acc = accuracy(preds, y, task=\"multiclass\", num_classes=nb_classes)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f'{stage}_loss', loss, prog_bar=True)\n",
    "            self.log(f'{stage}_accuracy', acc, prog_bar=True)\n",
    "\n",
    "        return loss, acc\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._evaluate(batch, batch_idx, 'val')[0]\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:19:15.801712Z",
     "iopub.status.busy": "2024-11-25T07:19:15.801401Z",
     "iopub.status.idle": "2024-11-25T07:19:16.114084Z",
     "shell.execute_reply": "2024-11-25T07:19:16.113359Z",
     "shell.execute_reply.started": "2024-11-25T07:19:15.801672Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 14, 14]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 14, 14]             128\n",
      "              ReLU-3           [-1, 64, 14, 14]               0\n",
      "         MaxPool2d-4             [-1, 64, 7, 7]               0\n",
      "            Conv2d-5             [-1, 64, 7, 7]          36,864\n",
      "       BatchNorm2d-6             [-1, 64, 7, 7]             128\n",
      "              ReLU-7             [-1, 64, 7, 7]               0\n",
      "            Conv2d-8             [-1, 64, 7, 7]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 7, 7]             128\n",
      "             ReLU-10             [-1, 64, 7, 7]               0\n",
      "       BasicBlock-11             [-1, 64, 7, 7]               0\n",
      "           Conv2d-12             [-1, 64, 7, 7]          36,864\n",
      "      BatchNorm2d-13             [-1, 64, 7, 7]             128\n",
      "             ReLU-14             [-1, 64, 7, 7]               0\n",
      "           Conv2d-15             [-1, 64, 7, 7]          36,864\n",
      "      BatchNorm2d-16             [-1, 64, 7, 7]             128\n",
      "             ReLU-17             [-1, 64, 7, 7]               0\n",
      "       BasicBlock-18             [-1, 64, 7, 7]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "             ReLU-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
      "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
      "             ReLU-26            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
      "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
      "             ReLU-30            [-1, 128, 4, 4]               0\n",
      "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "             ReLU-33            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
      "             ReLU-37            [-1, 256, 2, 2]               0\n",
      "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
      "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
      "             ReLU-42            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
      "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
      "             ReLU-46            [-1, 256, 2, 2]               0\n",
      "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
      "             ReLU-49            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
      "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-53            [-1, 512, 1, 1]               0\n",
      "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-58            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
      "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-62            [-1, 512, 1, 1]               0\n",
      "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-65            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 10]           5,130\n",
      "           ResNet-69                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 11,181,642\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 11,176,512\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.09\n",
      "Params size (MB): 42.65\n",
      "Estimated Total Size (MB): 43.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_time_string = datetime.datetime.utcnow().isoformat(timespec='minutes')\n",
    "filename = f'datalab_nn_pytorch_resnet_{run_time_string}'\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_accuracy',\n",
    "   min_delta=0.001,\n",
    "   patience=3,\n",
    "   verbose=True,\n",
    "   mode='max'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    dirpath='nn_results',\n",
    "    filename=filename,\n",
    "    verbose=True,\n",
    "    save_top_k=1\n",
    ")\n",
    "\n",
    "logger = [CSVLogger(\"nn_results2\", name=filename), TensorBoardLogger(\"nn_results\", name=filename)]\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "if device == \"gpu\":\n",
    "    myTrainer=pl.Trainer(callbacks=[early_stop_callback, checkpoint_callback], logger=logger,\n",
    "                     gpus=-1, accelerator='dp', auto_select_gpus=True, max_epochs=5)\n",
    "else:\n",
    "    myTrainer=pl.Trainer(callbacks=[early_stop_callback, checkpoint_callback], logger=logger,\n",
    "                         max_epochs=5)\n",
    "    \n",
    "model_resnet = myresnet().to(device)\n",
    "summary(model_resnet, input_size=(3, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:19:23.695348Z",
     "iopub.status.busy": "2024-11-25T07:19:23.694972Z",
     "iopub.status.idle": "2024-11-25T07:21:12.344932Z",
     "shell.execute_reply": "2024-11-25T07:21:12.343743Z",
     "shell.execute_reply.started": "2024-11-25T07:19:23.695314Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type    | Params | In sizes       | Out sizes\n",
      "---------------------------------------------------------------\n",
      "0 | model | ResNet  | 11.2 M | [1, 3, 28, 28] | [1, 10]  \n",
      "1 | loss  | NLLLoss | 0      | ?              | ?        \n",
      "---------------------------------------------------------------\n",
      "5.1 K     Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08dffc8c0b5d46f192cefd057f1557f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_accuracy improved. New best score: 0.129\n",
      "Epoch 0, global step 469: 'val_accuracy' reached 0.12947 (best 0.12947), saving model to 'nn_results/datalab_nn_pytorch_resnet_2024-11-25T07:19.ckpt' as top 1\n",
      "/home/aparsons/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "myTrainer.fit(model_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:21:19.626913Z",
     "iopub.status.busy": "2024-11-25T07:21:19.626499Z",
     "iopub.status.idle": "2024-11-25T07:21:19.633130Z",
     "shell.execute_reply": "2024-11-25T07:21:19.631888Z",
     "shell.execute_reply.started": "2024-11-25T07:21:19.626876Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:21:20.145711Z",
     "iopub.status.busy": "2024-11-25T07:21:20.144445Z",
     "iopub.status.idle": "2024-11-25T07:21:20.151799Z",
     "shell.execute_reply": "2024-11-25T07:21:20.150371Z",
     "shell.execute_reply.started": "2024-11-25T07:21:20.145644Z"
    }
   },
   "outputs": [],
   "source": [
    "#data_transforms = {\n",
    "#    'train': transforms.Compose([\n",
    "#        #transforms.Resize(28),\n",
    "#        transforms.RandomHorizontalFlip(),\n",
    "#        transforms.Grayscale(3), \n",
    "#        transforms.ToTensor(), \n",
    "#        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "#    ]),\n",
    "#    'test': transforms.Compose([\n",
    "#        #transforms.Resize(28),\n",
    "#        transforms.Grayscale(3),\n",
    "#        transforms.ToTensor(), \n",
    "#        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "#    ])\n",
    "#}\n",
    "#\n",
    "#trainset = FashionMNIST(root='./data', train=True, \n",
    "#                        download=True, transform=data_transforms['train'])\n",
    "#\n",
    "#trainset, valset = random_split(trainset, (50000,10000))\n",
    "#\n",
    "#trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, \n",
    "#                                          num_workers=4)\n",
    "#\n",
    "#testset = FashionMNIST(root='./data', train=False, \n",
    "#                       download=True,transform=data_transforms['test'])\n",
    "#\n",
    "#testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, \n",
    "#                                         num_workers=4)\n",
    "#\n",
    "#valloader = DataLoader(valset, batch_size=batch_size, shuffle=False, \n",
    "#                                         num_workers=4)\n",
    "#\n",
    "#classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "#           'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "#\n",
    "#\n",
    "#image_datasets = {'train': trainset, 'val': valset, 'test': testset}\n",
    "#dataloaders = {'train': trainloader, 'val': valloader, 'test': testloader}\n",
    "#dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "#\n",
    "#\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:21:21.229192Z",
     "iopub.status.busy": "2024-11-25T07:21:21.228292Z",
     "iopub.status.idle": "2024-11-25T07:21:21.249841Z",
     "shell.execute_reply": "2024-11-25T07:21:21.248907Z",
     "shell.execute_reply.started": "2024-11-25T07:21:21.229109Z"
    }
   },
   "outputs": [],
   "source": [
    "#dataloaders = {'train': train_loader, 'val': test_loader}\n",
    "def train_model(model, criterion, optimizer, scheduler, val_acc, \n",
    "                val_loss, train_acc, train_loss,epoch, \n",
    "                num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    list = {'train': {'acc': train_acc, 'loss': train_loss}, \n",
    "        'val':{'acc': val_acc, 'loss': val_loss}}\n",
    "    next = epoch\n",
    "    for epoch in range(next, next+num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, next + num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "        \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "        \n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "        \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "        \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "        \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            list[phase]['loss'].append(epoch_loss)\n",
    "            list[phase]['acc'].append(epoch_acc.item())\n",
    "        \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "        \n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "        \n",
    "    return model, epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:21:23.108091Z",
     "iopub.status.busy": "2024-11-25T07:21:23.107092Z",
     "iopub.status.idle": "2024-11-25T07:21:23.354067Z",
     "shell.execute_reply": "2024-11-25T07:21:23.353544Z",
     "shell.execute_reply.started": "2024-11-25T07:21:23.108005Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False\n",
    "\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:21:25.439317Z",
     "iopub.status.busy": "2024-11-25T07:21:25.438745Z",
     "iopub.status.idle": "2024-11-25T07:21:25.446540Z",
     "shell.execute_reply": "2024-11-25T07:21:25.445003Z",
     "shell.execute_reply.started": "2024-11-25T07:21:25.439266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lists for plotting loss and accuracy and variable to\n",
    "# keep track of the epoch.\n",
    "# Rerun this cell if you want to restart training to empty the lists.\n",
    "epoch = 0\n",
    "val_acc = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "train_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:21:26.325316Z",
     "iopub.status.busy": "2024-11-25T07:21:26.325043Z",
     "iopub.status.idle": "2024-11-25T07:24:10.418377Z",
     "shell.execute_reply": "2024-11-25T07:24:10.417067Z",
     "shell.execute_reply.started": "2024-11-25T07:21:26.325298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.5311 Acc: 0.8123\n",
      "val Loss: 0.3462 Acc: 0.8706\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.3006 Acc: 0.8908\n",
      "val Loss: 0.2939 Acc: 0.8936\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.2522 Acc: 0.9074\n",
      "val Loss: 0.2774 Acc: 0.9008\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.2228 Acc: 0.9188\n",
      "val Loss: 0.2638 Acc: 0.9067\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.2002 Acc: 0.9257\n",
      "val Loss: 0.2598 Acc: 0.9095\n",
      "\n",
      "Training complete in 2m 44s\n",
      "Best val Acc: 0.909500\n"
     ]
    }
   ],
   "source": [
    "model, epoch = train_model(model, criterion, optimizer, scheduler, val_acc, val_loss,  train_acc, train_loss, epoch, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:25:07.574280Z",
     "iopub.status.busy": "2024-11-25T07:25:07.573908Z",
     "iopub.status.idle": "2024-11-25T07:25:07.719781Z",
     "shell.execute_reply": "2024-11-25T07:25:07.719236Z",
     "shell.execute_reply.started": "2024-11-25T07:25:07.574248Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save({'epoch' : epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss, 'val_loss': val_loss, \n",
    "            'train_acc': train_acc, 'val_acc': val_acc}, \n",
    "           './FMNIST_ResNet18_noresize.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:25:21.352912Z",
     "iopub.status.busy": "2024-11-25T07:25:21.352010Z",
     "iopub.status.idle": "2024-11-25T07:25:21.442820Z",
     "shell.execute_reply": "2024-11-25T07:25:21.441840Z",
     "shell.execute_reply.started": "2024-11-25T07:25:21.352872Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./FMNIST_ResNet18_noresize.tar')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])  \n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "train_loss = checkpoint['train_loss']\n",
    "train_acc = checkpoint['train_acc']\n",
    "val_loss = checkpoint['val_loss']\n",
    "val_acc = checkpoint['val_acc']\n",
    "epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "RDMy90B6-PEy",
    "IXWdI2td-PE5"
   ],
   "name": "02_CNNs-pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
