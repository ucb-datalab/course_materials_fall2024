{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:25:03.052535Z",
     "iopub.status.busy": "2024-11-25T18:25:03.052119Z",
     "iopub.status.idle": "2024-11-25T18:25:03.055371Z",
     "shell.execute_reply": "2024-11-25T18:25:03.054758Z",
     "shell.execute_reply.started": "2024-11-25T18:25:03.052506Z"
    },
    "id": "ai72An86lqSS"
   },
   "outputs": [],
   "source": [
    "# do this step below to get lightning, lightning bolts, etc.\n",
    "# !pip install lightning-bolts torchvision torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kdonR3h-PEn"
   },
   "source": [
    "# Classification Revisited, with ResNets\n",
    "\n",
    "*AY 128/256 (UC Berkeley, 2018â€“2024)*\n",
    "\n",
    "Previously, we used CNNs in our own custom model to classify images. You are asked to stack up your own model to classify galaxies in Lab 3, and you should definitely explore different CNN depths, kernel sizes, and filters to get a feel for how this works. Many of them will be able to perform the functions you need for Lab 3 adequately. That said, some architectures are better than others, and an architecture we are going to introduce today, **ResNets (Residual neural Networks)** are particularly efficient at image classification.\n",
    "\n",
    "More generally, PyTorch comes with a bunch of models and pre-trained weights that come from fitting to some generic (in this case classification) data sets. As it turns out, many of the features in these trained CNNs are widely applicable and can be easily repurposed for another task. In this lecture, we will explore how to do that.\n",
    "\n",
    "Again, we'll make use of the Fashion MNIST labeled dataset, which you may recall looked something like this:\n",
    "\n",
    "<img src=\"https://github.com/zalandoresearch/fashion-mnist/blob/master/doc/img/fashion-mnist-sprite.png?raw=true\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJxs6AOJ-PEp"
   },
   "source": [
    "With labels: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:25:03.056616Z",
     "iopub.status.busy": "2024-11-25T18:25:03.056136Z",
     "iopub.status.idle": "2024-11-25T18:25:03.068904Z",
     "shell.execute_reply": "2024-11-25T18:25:03.068266Z",
     "shell.execute_reply.started": "2024-11-25T18:25:03.056585Z"
    },
    "id": "5B6atmbVWAa7"
   },
   "outputs": [],
   "source": [
    "lookup = {0: \"T-shirt/top\",\n",
    "          1: \"Trouser\",\n",
    "          2: \"Pullover\",\n",
    "          3: \"Dress\",\n",
    "          4: \"Coat\",\n",
    "          5: \"Sandal\",\n",
    "          6: \"Shirt\",\n",
    "          7: \"Sneaker\",\n",
    "          8: \"Bag\",\n",
    "          9: \"Ankle boot\"}\n",
    "\n",
    "def output_label(label):\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\n",
    "    return lookup[input]\n",
    "\n",
    "nb_classes = len(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:25:03.069939Z",
     "iopub.status.busy": "2024-11-25T18:25:03.069650Z",
     "iopub.status.idle": "2024-11-25T18:25:06.526581Z",
     "shell.execute_reply": "2024-11-25T18:25:06.526005Z",
     "shell.execute_reply.started": "2024-11-25T18:25:03.069914Z"
    },
    "id": "0o566vXl-PEq",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 2.3.0+cu121\n",
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import datetime, os\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import accuracy\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, ModelSummary\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# use a GPU or MPS (Mac) if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "\n",
    "print(\"pytorch version:\", torch.__version__)\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:25:06.527465Z",
     "iopub.status.busy": "2024-11-25T18:25:06.527205Z",
     "iopub.status.idle": "2024-11-25T18:25:10.946398Z",
     "shell.execute_reply": "2024-11-25T18:25:10.945795Z",
     "shell.execute_reply.started": "2024-11-25T18:25:06.527448Z"
    },
    "id": "uG5avg7hiTtx"
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"../Lecture20_lab3_pytorch/fashion-mnist_train.csv.gz\")\n",
    "test_csv = pd.read_csv(\"../Lecture20_lab3_pytorch/fashion-mnist_test.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:25:10.947219Z",
     "iopub.status.busy": "2024-11-25T18:25:10.947052Z",
     "iopub.status.idle": "2024-11-25T18:25:10.951878Z",
     "shell.execute_reply": "2024-11-25T18:25:10.951247Z",
     "shell.execute_reply.started": "2024-11-25T18:25:10.947204Z"
    },
    "id": "OOL83YFQiTty"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting fashion_dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile fashion_dataset.py\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, data, transform = None):\n",
    "        \"\"\"Method to initilaize variables.\"\"\" \n",
    "        self.fashion_MNIST = list(data.values)\n",
    "        self.transform = transform\n",
    "        \n",
    "        label = []\n",
    "        image = []\n",
    "        \n",
    "        for i in self.fashion_MNIST:\n",
    "             # first column is of labels.\n",
    "            label.append(i[0])\n",
    "            image.append(i[1:])\n",
    "        self.labels = np.asarray(label)\n",
    "        # Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\n",
    "        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:25:10.953928Z",
     "iopub.status.busy": "2024-11-25T18:25:10.953660Z",
     "iopub.status.idle": "2024-11-25T18:25:10.966482Z",
     "shell.execute_reply": "2024-11-25T18:25:10.965983Z",
     "shell.execute_reply.started": "2024-11-25T18:25:10.953864Z"
    }
   },
   "outputs": [],
   "source": [
    "from fashion_dataset import FashionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:25:10.967443Z",
     "iopub.status.busy": "2024-11-25T18:25:10.967260Z",
     "iopub.status.idle": "2024-11-25T18:25:11.374962Z",
     "shell.execute_reply": "2024-11-25T18:25:11.374459Z",
     "shell.execute_reply.started": "2024-11-25T18:25:10.967427Z"
    },
    "id": "OOL83YFQiTty"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "## Transform data into Tensor that has a range from 0 to 1\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.RandomAffine(degrees=15, shear=0.1),\n",
    "        #transforms.Resize(28),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Grayscale(3), \n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.RandomAffine(degrees=15, shear=0.1),\n",
    "        #transforms.Resize(28),\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "}\n",
    "\n",
    "train_set = FashionDataset(train_csv, transform=data_transforms['train'])\n",
    "test_set = FashionDataset(test_csv, transform=data_transforms['test'])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=2)\n",
    "test_loader = DataLoader(train_set, batch_size=batch_size, num_workers=2)\n",
    "\n",
    "train_label = torch.tensor([train_set[i][1] for i in range(nb_classes)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRlyeM7J-PE3"
   },
   "source": [
    "## Our (Previous) CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the model we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:25:11.375892Z",
     "iopub.status.busy": "2024-11-25T18:25:11.375720Z",
     "iopub.status.idle": "2024-11-25T18:25:11.387437Z",
     "shell.execute_reply": "2024-11-25T18:25:11.386590Z",
     "shell.execute_reply.started": "2024-11-25T18:25:11.375876Z"
    },
    "id": "Ftp5zXGFpi29"
   },
   "outputs": [],
   "source": [
    "class mycnn_dropout(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # define the layers here\n",
    "        # Conv2d(in_channels, out_channels, kernel_size)\n",
    "        # see https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "        self.layer1 = nn.Sequential(\n",
    "            #nn.Conv2d(1, 32, kernel_size=3),\n",
    "            nn.Conv2d(3, 32, kernel_size=3),\n",
    "            \n",
    "            # see https://github.com/sksq96/pytorch-summary/issues/55#issuecomment-471844028\n",
    "            # to understand why pytorch and keras differ here\n",
    "            nn.BatchNorm2d(32, affine=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(p=0.1)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fc1=torch.nn.Linear(1152, 32)\n",
    "        self.fc2=torch.nn.Linear(32, 10)\n",
    "    \n",
    "        self.loss = nn.NLLLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # add dropout \n",
    "        x = nn.Dropout(p=0.2)(x)\n",
    "\n",
    "        x=torch.relu(self.fc1(x))\n",
    "        x=F.log_softmax(self.fc2(x), dim=-1)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.75,\n",
    "            patience=2,\n",
    "            min_lr=1e-6,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_accuracy\"}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def _evaluate(self, batch, batch_idx, stage=None):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        acc = accuracy(preds, y, task=\"multiclass\", num_classes=nb_classes)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f'{stage}_loss', loss, prog_bar=True)\n",
    "            self.log(f'{stage}_accuracy', acc, prog_bar=True)\n",
    "\n",
    "        return loss, acc\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._evaluate(batch, batch_idx, 'val')[0]\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:25:11.388906Z",
     "iopub.status.busy": "2024-11-25T18:25:11.388387Z",
     "iopub.status.idle": "2024-11-25T18:25:11.887504Z",
     "shell.execute_reply": "2024-11-25T18:25:11.886826Z",
     "shell.execute_reply.started": "2024-11-25T18:25:11.388844Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "/home/aparsons/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/aparsons/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "  rank_zero_deprecation(\n",
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: nn_results/datalab_nn_pytorch_dropout_2024-11-25T15:53.ckpt\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             896\n",
      "       BatchNorm2d-2           [-1, 32, 26, 26]               0\n",
      "              ReLU-3           [-1, 32, 26, 26]               0\n",
      "         MaxPool2d-4           [-1, 32, 13, 13]               0\n",
      "            Conv2d-5           [-1, 64, 11, 11]          18,496\n",
      "              ReLU-6           [-1, 64, 11, 11]               0\n",
      "         MaxPool2d-7             [-1, 64, 5, 5]               0\n",
      "           Dropout-8             [-1, 64, 5, 5]               0\n",
      "            Conv2d-9            [-1, 128, 3, 3]          73,856\n",
      "             ReLU-10            [-1, 128, 3, 3]               0\n",
      "           Linear-11                   [-1, 32]          36,896\n",
      "           Linear-12                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 130,474\n",
      "Trainable params: 130,474\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.70\n",
      "Params size (MB): 0.50\n",
      "Estimated Total Size (MB): 1.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_time_string = datetime.datetime.utcnow().isoformat(timespec='minutes')\n",
    "filename = f'datalab_nn_pytorch_dropout_{run_time_string}'\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_accuracy',\n",
    "   min_delta=0.001,\n",
    "   patience=3,\n",
    "   verbose=True,\n",
    "   mode='max'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    dirpath='nn_results',\n",
    "    filename=filename,\n",
    "    verbose=True,\n",
    "    save_top_k=1\n",
    ")\n",
    "\n",
    "logger = [CSVLogger(\"nn_results1\", name=filename), TensorBoardLogger(\"nn_results1\", name=filename)]\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    myTrainer=pl.Trainer(callbacks=[early_stop_callback, checkpoint_callback], logger=logger,\n",
    "                     gpus=-1, accelerator='cuda', auto_select_gpus=True, max_epochs=5)\n",
    "else:\n",
    "    myTrainer=pl.Trainer(callbacks=[early_stop_callback, checkpoint_callback], logger=logger,\n",
    "                         max_epochs=5)\n",
    "if True:\n",
    "    cpt = !ls -td nn_results/*\n",
    "    cpt = cpt[0]\n",
    "    print('Reading from:', cpt)\n",
    "    model_dropout = mycnn_dropout.load_from_checkpoint(cpt).to(device)\n",
    "else:\n",
    "    model_dropout = mycnn_dropout().to(device)\n",
    "\n",
    "#summary(model_dropout.to(device), input_size=(1, 28, 28))\n",
    "summary(model_dropout, input_size=(3, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:25:11.888835Z",
     "iopub.status.busy": "2024-11-25T18:25:11.888562Z",
     "iopub.status.idle": "2024-11-25T18:27:53.238568Z",
     "shell.execute_reply": "2024-11-25T18:27:53.237542Z",
     "shell.execute_reply.started": "2024-11-25T18:25:11.888810Z"
    },
    "id": "pTooZRBQqHZq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aparsons/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory nn_results exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/aparsons/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | layer1 | Sequential | 896   \n",
      "1 | layer2 | Sequential | 18.5 K\n",
      "2 | layer3 | Sequential | 73.9 K\n",
      "3 | fc1    | Linear     | 36.9 K\n",
      "4 | fc2    | Linear     | 330   \n",
      "5 | loss   | NLLLoss    | 0     \n",
      "--------------------------------------\n",
      "130 K     Trainable params\n",
      "0         Non-trainable params\n",
      "130 K     Total params\n",
      "0.522     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aparsons/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/aparsons/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521b332d414448c081b8b6e0be3d1fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aparsons/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_accuracy improved. New best score: 0.893\n",
      "Epoch 0, global step 469: 'val_accuracy' reached 0.89308 (best 0.89308), saving model to 'nn_results/datalab_nn_pytorch_dropout_2024-11-25T18:25.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 938: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_accuracy improved by 0.004 >= min_delta = 0.001. New best score: 0.897\n",
      "Epoch 2, global step 1407: 'val_accuracy' reached 0.89705 (best 0.89705), saving model to 'nn_results/datalab_nn_pytorch_dropout_2024-11-25T18:25.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1876: 'val_accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_accuracy improved by 0.004 >= min_delta = 0.001. New best score: 0.901\n",
      "Epoch 4, global step 2345: 'val_accuracy' reached 0.90067 (best 0.90067), saving model to 'nn_results/datalab_nn_pytorch_dropout_2024-11-25T18:25.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "myTrainer.fit(model_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:29:33.401213Z",
     "iopub.status.busy": "2024-11-25T18:29:33.401018Z",
     "iopub.status.idle": "2024-11-25T18:29:33.404086Z",
     "shell.execute_reply": "2024-11-25T18:29:33.403649Z",
     "shell.execute_reply.started": "2024-11-25T18:29:33.401197Z"
    },
    "id": "pTooZRBQqHZq"
   },
   "outputs": [],
   "source": [
    "#model_dropout.eval()  # Set the model to evaluation mode\n",
    "## get a batch of data from the test set\n",
    "#data = next(iter(test_loader))\n",
    "#example_input = data[0].to(device)\n",
    "#\n",
    "## Get predictions\n",
    "#with torch.no_grad():  # Disable gradient calculation\n",
    "#    predictions = model_dropout(example_input)\n",
    "#\n",
    "## If you want the class with the highest probability\n",
    "#predicted_class = torch.argmax(predictions, dim=1)\n",
    "#\n",
    "#print(predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNets\n",
    "ResNets are a neural net architecture designed for image classification tasks, but they have a long (for machine learning) history dating back to the 1980s.\n",
    "Generally, they are a solution to the problem that deep neural nets can \"lose track\" of image information in nets that aren't already well-trained. This makes it hard\n",
    "for gradients to be propagated deep into the network to identify useful features. The solution was to introduce \n",
    "skip connections (residual connections, or identity maps) between stacks of convolutional layers to allow gradients to flow directly through the network, mitigating the vanishing gradient problem in very deep networks.\n",
    "The residual blocks allow the model to learn identity mappings easily, making it more robust for deep architectures.\n",
    "\n",
    "<img src=\"ResBlock.png\" width=\"20%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Original-ResNet-18-Architecture.png\" width=\"50%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course, there are many flavors of residual networks with varying depths and numbers of parameters:\n",
    "\n",
    "<img src=\"resnet_param_counts.png\" width=\"50%\">\n",
    "\n",
    "This general architecture, whereby earlier layers are fed forward with intermediate layers providing augmented context, is also very widely used, including\n",
    "in U-Nets (used for image segmentation), Transformer networks (e.g. the \"T\" in GPT), and many others. But because we are interested in image classification,\n",
    "we'll start with ResNets here.\n",
    "\n",
    "Here's an example of some of the intermediate layers of a ResNet-18 that was trained on a very large and generic set of millions of labeled images, and is now being shown a hops berry (I think?).\n",
    "\n",
    "<img src=\"resnet_feature_visual.png\" width=\"50%\">\n",
    "\n",
    "What's interesting here is how generic the filter shapes are, especially in the first few layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous lecture, we examined how important it was to have large training sets, and to augment our training sets with transformations in order to avoid overfitting.\n",
    "Well, it turns out that training a ResNet on a huge number of images that have nothing to do with galaxies or fashion (or both?) can lead it to identify features\n",
    "that are generally usefull for image classification, and these features can help jump-start galaxy classification.\n",
    "\n",
    "Even better, someone else spend a huge amount of computing time getting you these weights, so you can leverage trainings that might have taken months on large GPU clusters to run.\n",
    "\n",
    "Harnessing pre-trained networks for new tasks is called **learning transfer**, and it can be quite powerful.\n",
    "The trick is knowning where to create the splice between your pre-trained network and a custom network that focuses on your particular task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch ResNet-18 (with Lightning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:29:38.870131Z",
     "iopub.status.busy": "2024-11-25T18:29:38.869929Z",
     "iopub.status.idle": "2024-11-25T18:29:38.876872Z",
     "shell.execute_reply": "2024-11-25T18:29:38.876350Z",
     "shell.execute_reply.started": "2024-11-25T18:29:38.870113Z"
    }
   },
   "outputs": [],
   "source": [
    "# Version of ResNet in Lightning, paralleling structure above\n",
    "\n",
    "class myresnet(pl.LightningModule):\n",
    "    def __init__(self, num_classes=nb_classes):\n",
    "        super(myresnet, self).__init__()\n",
    "        \n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        # Freeze all layers initially (so their weights don't update)\n",
    "        #for param in self.model.parameters():\n",
    "        #    param.requires_grad = False\n",
    "\n",
    "        # Modify the final fully connected layer to match the number of classes\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "        # Unfreeze specific layers (e.g., the final fully connected layer)\n",
    "        #for param in self.model.fc.parameters():\n",
    "        #    param.requires_grad = True\n",
    "\n",
    "        #self.loss = nn.CrossEntropyLoss()\n",
    "        self.loss = nn.NLLLoss()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        #x = F.log_softmax(x, dim=-1)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.75,\n",
    "            patience=2,\n",
    "            min_lr=1e-6,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_accuracy\"}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def _evaluate(self, batch, batch_idx, stage=None):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        acc = accuracy(preds, y, task=\"multiclass\", num_classes=nb_classes)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f'{stage}_loss', loss, prog_bar=True)\n",
    "            self.log(f'{stage}_accuracy', acc, prog_bar=True)\n",
    "\n",
    "        return loss, acc\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._evaluate(batch, batch_idx, 'val')[0]\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:29:39.368734Z",
     "iopub.status.busy": "2024-11-25T18:29:39.368445Z",
     "iopub.status.idle": "2024-11-25T18:29:39.802704Z",
     "shell.execute_reply": "2024-11-25T18:29:39.802085Z",
     "shell.execute_reply.started": "2024-11-25T18:29:39.368715Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/aparsons/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "/home/aparsons/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/aparsons/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 14, 14]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 14, 14]             128\n",
      "              ReLU-3           [-1, 64, 14, 14]               0\n",
      "         MaxPool2d-4             [-1, 64, 7, 7]               0\n",
      "            Conv2d-5             [-1, 64, 7, 7]          36,864\n",
      "       BatchNorm2d-6             [-1, 64, 7, 7]             128\n",
      "              ReLU-7             [-1, 64, 7, 7]               0\n",
      "            Conv2d-8             [-1, 64, 7, 7]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 7, 7]             128\n",
      "             ReLU-10             [-1, 64, 7, 7]               0\n",
      "       BasicBlock-11             [-1, 64, 7, 7]               0\n",
      "           Conv2d-12             [-1, 64, 7, 7]          36,864\n",
      "      BatchNorm2d-13             [-1, 64, 7, 7]             128\n",
      "             ReLU-14             [-1, 64, 7, 7]               0\n",
      "           Conv2d-15             [-1, 64, 7, 7]          36,864\n",
      "      BatchNorm2d-16             [-1, 64, 7, 7]             128\n",
      "             ReLU-17             [-1, 64, 7, 7]               0\n",
      "       BasicBlock-18             [-1, 64, 7, 7]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "             ReLU-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
      "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
      "             ReLU-26            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
      "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
      "             ReLU-30            [-1, 128, 4, 4]               0\n",
      "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "             ReLU-33            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
      "             ReLU-37            [-1, 256, 2, 2]               0\n",
      "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
      "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
      "             ReLU-42            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
      "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
      "             ReLU-46            [-1, 256, 2, 2]               0\n",
      "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
      "             ReLU-49            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
      "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-53            [-1, 512, 1, 1]               0\n",
      "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-58            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
      "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-62            [-1, 512, 1, 1]               0\n",
      "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-65            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 10]           5,130\n",
      "           ResNet-69                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 11,181,642\n",
      "Trainable params: 11,181,642\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.09\n",
      "Params size (MB): 42.65\n",
      "Estimated Total Size (MB): 43.75\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aparsons/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "run_time_string = datetime.datetime.utcnow().isoformat(timespec='minutes')\n",
    "filename = f'datalab_nn_pytorch_resnet_{run_time_string}'\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_accuracy',\n",
    "   min_delta=0.001,\n",
    "   patience=3,\n",
    "   verbose=True,\n",
    "   mode='max'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    dirpath='nn_results',\n",
    "    filename=filename,\n",
    "    verbose=True,\n",
    "    save_top_k=1\n",
    ")\n",
    "\n",
    "logger = [CSVLogger(\"nn_results2\", name=filename), TensorBoardLogger(\"nn_results\", name=filename)]\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "if device == \"gpu\":\n",
    "    myTrainer=pl.Trainer(callbacks=[early_stop_callback, checkpoint_callback], logger=logger,\n",
    "                     gpus=-1, accelerator='dp', auto_select_gpus=True, max_epochs=5)\n",
    "else:\n",
    "    myTrainer=pl.Trainer(callbacks=[early_stop_callback, checkpoint_callback], logger=logger,\n",
    "                         max_epochs=5)\n",
    "    \n",
    "model_resnet = myresnet().to(device)\n",
    "summary(model_resnet, input_size=(3, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:29:39.804937Z",
     "iopub.status.busy": "2024-11-25T18:29:39.804200Z",
     "iopub.status.idle": "2024-11-25T18:29:39.808633Z",
     "shell.execute_reply": "2024-11-25T18:29:39.807994Z",
     "shell.execute_reply.started": "2024-11-25T18:29:39.804892Z"
    }
   },
   "outputs": [],
   "source": [
    "# Slow for reason I haven't tracked down yet.\n",
    "#myTrainer.fit(model_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch ResNet-18 (without Lightning)\n",
    "\n",
    "See https://colab.research.google.com/github/palver7/deeplearning/blob/master/FashionMNIST_with_ResNet18_no_resize.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:29:45.388620Z",
     "iopub.status.busy": "2024-11-25T18:29:45.388004Z",
     "iopub.status.idle": "2024-11-25T18:29:45.481934Z",
     "shell.execute_reply": "2024-11-25T18:29:45.481341Z",
     "shell.execute_reply.started": "2024-11-25T18:29:45.388550Z"
    }
   },
   "outputs": [],
   "source": [
    "# We'll could re-use the code above from previous lectures, but this is a stand-alone non-lighting version\n",
    "# of a data-loader\n",
    "#dataloaders = {'train': train_loader, 'val': test_loader}\n",
    "#dataset_sizes = {'train': len(train_loader.dataset.images), 'val': len(test_loader.dataset.images)}\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "samples = 64 #num of sample per batch\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.Resize(28),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Grayscale(3), \n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        #transforms.Resize(28),\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "}\n",
    "\n",
    "trainset = FashionMNIST(root='./data', train=True, \n",
    "                        download=True, transform=data_transforms['train'])\n",
    "\n",
    "trainset, valset = random_split(trainset, (50000,10000))\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=samples, shuffle=True, \n",
    "                                          num_workers=4)\n",
    "\n",
    "testset = FashionMNIST(root='./data', train=False, \n",
    "                       download=True,transform=data_transforms['test'])\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=samples, shuffle=False, \n",
    "                                         num_workers=4)\n",
    "samples\n",
    "valloader = DataLoader(valset, batch_size=samples, shuffle=False, \n",
    "                                         num_workers=4)\n",
    "\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "           'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "\n",
    "image_datasets = {'train': trainset, 'val': valset, 'test': testset}\n",
    "dataloaders = {'train': trainloader, 'val': valloader, 'test': testloader}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:29:45.997767Z",
     "iopub.status.busy": "2024-11-25T18:29:45.997196Z",
     "iopub.status.idle": "2024-11-25T18:29:46.016013Z",
     "shell.execute_reply": "2024-11-25T18:29:46.015084Z",
     "shell.execute_reply.started": "2024-11-25T18:29:45.997723Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, val_acc, \n",
    "                val_loss, train_acc, train_loss,epoch, \n",
    "                num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    list = {'train': {'acc': train_acc, 'loss': train_loss}, \n",
    "        'val':{'acc': val_acc, 'loss': val_loss}}\n",
    "    next = epoch\n",
    "    for epoch in range(next, next+num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, next + num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "        \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "        \n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "        \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "        \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "        \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            list[phase]['loss'].append(epoch_loss)\n",
    "            list[phase]['acc'].append(epoch_acc.item())\n",
    "        \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "        \n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "        \n",
    "    return model, epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:29:46.944205Z",
     "iopub.status.busy": "2024-11-25T18:29:46.943339Z",
     "iopub.status.idle": "2024-11-25T18:29:47.191199Z",
     "shell.execute_reply": "2024-11-25T18:29:47.190523Z",
     "shell.execute_reply.started": "2024-11-25T18:29:46.944132Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "model.fc = nn.Linear(model.fc.in_features, nb_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) # Decay LR by a factor of 0.1 every 7 epochs\n",
    "\n",
    "# load in previous save state, if available\n",
    "if False:\n",
    "    checkpoint = torch.load('./FMNIST_ResNet18_noresize.tar')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])  \n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    train_loss = checkpoint['train_loss']\n",
    "    train_acc = checkpoint['train_acc']\n",
    "    val_loss = checkpoint['val_loss']\n",
    "    val_acc = checkpoint['val_acc']\n",
    "    epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:29:47.679538Z",
     "iopub.status.busy": "2024-11-25T18:29:47.678708Z",
     "iopub.status.idle": "2024-11-25T18:29:47.688036Z",
     "shell.execute_reply": "2024-11-25T18:29:47.686324Z",
     "shell.execute_reply.started": "2024-11-25T18:29:47.679458Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "val_acc = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "train_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:29:49.300715Z",
     "iopub.status.busy": "2024-11-25T18:29:49.300158Z",
     "iopub.status.idle": "2024-11-25T18:31:54.579168Z",
     "shell.execute_reply": "2024-11-25T18:31:54.578374Z",
     "shell.execute_reply.started": "2024-11-25T18:29:49.300627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aparsons/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4829 Acc: 0.8280\n",
      "val Loss: 0.3156 Acc: 0.8870\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.2950 Acc: 0.8929\n",
      "val Loss: 0.2787 Acc: 0.9001\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.2525 Acc: 0.9085\n",
      "val Loss: 0.2590 Acc: 0.9057\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.2247 Acc: 0.9178\n",
      "val Loss: 0.2358 Acc: 0.9133\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.2024 Acc: 0.9252\n",
      "val Loss: 0.2299 Acc: 0.9159\n",
      "\n",
      "Training complete in 2m 5s\n",
      "Best val Acc: 0.915900\n"
     ]
    }
   ],
   "source": [
    "model, epoch = train_model(model, criterion, optimizer, scheduler, val_acc, val_loss,  train_acc, train_loss, epoch, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T18:31:54.580737Z",
     "iopub.status.busy": "2024-11-25T18:31:54.580495Z",
     "iopub.status.idle": "2024-11-25T18:31:54.810098Z",
     "shell.execute_reply": "2024-11-25T18:31:54.807223Z",
     "shell.execute_reply.started": "2024-11-25T18:31:54.580713Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save({'epoch' : epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss, 'val_loss': val_loss, \n",
    "            'train_acc': train_acc, 'val_acc': val_acc}, \n",
    "           './FMNIST_ResNet18_noresize.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "RDMy90B6-PEy",
    "IXWdI2td-PE5"
   ],
   "name": "02_CNNs-pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
