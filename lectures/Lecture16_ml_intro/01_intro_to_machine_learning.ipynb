{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "<img src=\"https://static1.squarespace.com/static/5150aec6e4b0e340ec52710a/t/51525c33e4b0b3e0d10f77ab/1364352052403/Data_Science_VD.png?format=250w\">\n",
    "\n",
    "http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "> Field of study that give computers the ability to learn without being explicitly programmed.\n",
    "> -Arthur Samuel, 1959\n",
    "\n",
    "<b>Short  Answer</b>:  The offspring of Statistics and Computer Science\n",
    "\n",
    "<b>Better Answer</b>:  A set of models which aim to learn something about a data set to apply that knowledge to new data\n",
    "\n",
    "<u>Utility</u>\n",
    "\n",
    " - Using labels from training data to classify new objects (e.g., images, digits, webpages)\n",
    " - Learning the relationship between explanatory features and response variable to predict for new data (e.g., stock market)\n",
    " - Discovering natural clustering structure in data\n",
    " - Detecting low-dimensional structure in high-dimensional data\n",
    " - Finding outliers in large data sets\n",
    " - Game playing/Robotics\n",
    " \n",
    " >   *Essentially, all models are wrong, but some are useful.*\n",
    " \n",
    " >     -- George Box, Statistician (1919-2013)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating the Terminology \n",
    "\n",
    "<img src=\"figs/term.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Types of Learning\n",
    "\n",
    "<img src=\"figs/three.png\">\n",
    "\n",
    "From: [S. Raschka (2015)](https://www.slideshare.net/SebastianRaschka/nextgen-talk-022015/8-Learning_Labeled_data_Direct_feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised vs. Unsupervised Learning \n",
    "\n",
    "<img src=\"figs/learn_types.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Supervised Learning: Regression\n",
    "\n",
    "Use training set of $(\\vec x,y)$ pairs to learn to predict $y$ for new $\\vec x$. **Regression** is predicting a *continuous* outcome ($y$) variable from a vector of input features ($\\vec x$). That is, we seek to learn:\n",
    "\n",
    "$f(\\vec x) = y$\n",
    "\n",
    " In \"theory-driven\" MCMC modeling, we already think we know from physics what the functional form of $f$ is and what we try to do is figure out the parameters of $f$ that best accommodate the data we have and the beliefs we start with. When we do not know a functional form for $f$ we take more \"data driven\" approach, such as with Gaussian Processes.\n",
    "\n",
    "In `sklearn` there are a lot of \"data driven\" modelling possibilities.\n",
    "\n",
    "- Linear Regression:  `linear_model.LinearRegression`\n",
    "- Lasso & Ridge Reg.:  `linear_model.Lasso` / `linear_model.Ridge`\n",
    "- Gaussian Process Regression: `gaussian_process.GaussianProcess`\n",
    "- Nearest Neighbor Regression:  `neighbors.KNeighborsRegressor`\n",
    "- Support Vector Regression:   `svm.SVR`\n",
    "- Regression Trees:  `tree.DecisionTreeRegressor`\n",
    "\n",
    "An aside on the \"data driven\" vs \"theory driven\" distinction..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression ## \n",
    "\n",
    "Let's take a look at the famous California Housing data. We don't have a good physics model for this (of course there are economic theories...). for now we just have data and seek a data-driven model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib import cm\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X = housing['data']  # 8 features (e.g. HouseAge,Latitude, AveBedrms, etc.)\n",
    "Y = housing['target']  # response (median house price in $100,000)\n",
    "\n",
    "df = pd.DataFrame(X, columns=housing.feature_names)\n",
    "df[\"target\"]  = housing['target']\n",
    "\n",
    "# separate out the target into 5 different bins (for viz purposes)\n",
    "nbins = 5\n",
    "df[\"target_binned\"] = pd.qcut(df[\"target\"], nbins, labels=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"feature vector shape=\", X.shape)\n",
    "print(\"output shape=\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, 3, figsize=(12,6))\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.scatter(X[:, i], Y, alpha=0.2, s=2)\n",
    "    ax.set_xlabel(housing.feature_names[i])\n",
    "    ax.set_ylabel(\"Median House Price (in $100,000)\")\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "point_size = 80*(Y/max(Y))**3\n",
    "\n",
    "df1 = df[['MedInc', 'HouseAge', 'AveBedrms', \"target_binned\"]]\n",
    "colors = sns.color_palette(\"colorblind\", nbins)\n",
    "\n",
    "g= sns.pairplot(df1, hue=\"target_binned\", palette=sns.color_palette(\"cubehelix\", nbins),\n",
    "                         plot_kws=dict(s=2, edgecolor=None, alpha=0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model Fitting\n",
    "\n",
    "We need to create a **training set** and a **testing set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# half of data\n",
    "import math\n",
    "half = math.floor(len(Y)/2)\n",
    "train_X = X[:half]\n",
    "train_Y = Y[:half]\n",
    "test_X = X[half:]\n",
    "test_Y = Y[half:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "The following are a set of methods intended for regression in which the target value is expected to be a linear combination of the input variables. In mathematical notion, if $\\hat{y}$ is the predicted value.\n",
    "$$\\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p$$\n",
    "Across the module, we designate the vector $w = (w_1,\n",
    "..., w_p)$ as `coef_` and $w_0$ as `intercept_`.\n",
    "To perform classification with generalized linear models, see Logistic regression.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "clf = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "clf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the prediction\n",
    "Y_lr_pred = clf.predict(test_X)\n",
    "\n",
    "# how well did we do?\n",
    "mse = mean_squared_error(test_Y,Y_lr_pred) ; print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(test_Y,Y_lr_pred - test_Y, s=2, alpha=0.3)\n",
    "ax.set_title(\"Linear Regression Residuals - MSE = %.2f\" % mse)\n",
    "ax.set_xlabel(\"True Median House Price ($100,000)\")\n",
    "ax.set_ylabel(\"Residual\")\n",
    "ax.hlines(0,min(test_Y),max(test_Y),color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *k*-Nearest Neighbor (KNN) Regression\n",
    "\n",
    "\"The principle behind nearest neighbor methods is to find a predefined number of training samples closest in distance to the new point, and predict the label from these. The number of samples can be a user-defined constant (k-nearest neighbor learning), or vary based on the local density of points (radius-based neighbor learning). The distance can, in general, be any metric measure: standard Euclidean distance is the most common choice. Neighbors-based methods are known as non-generalizing machine learning methods, since they simply “remember” all of its training data (possibly transformed into a fast indexing structure such as a Ball Tree or KD Tree.).\"\n",
    "\n",
    "<img src=\"http://scikit-learn.org/stable/_images/sphx_glr_plot_regression_001.png\">\n",
    "\n",
    "http://scikit-learn.org/stable/modules/neighbors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# many methods work better on scaled X\n",
    "scaler = preprocessing.PowerTransformer() \n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "clf1 = neighbors.KNeighborsRegressor(5)\n",
    "\n",
    "# scale\n",
    "train_X = X_scaled[:half]\n",
    "test_X = X_scaled[half:]\n",
    "\n",
    "# not scaled\n",
    "#train_X = X[:half]\n",
    "#test_X = X[half:]\n",
    "\n",
    "clf1.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_knn_pred = clf1.predict(test_X)\n",
    "mse = mean_squared_error(test_Y,Y_knn_pred) ; print(mse)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.plot(test_Y, Y_knn_pred - test_Y, 'o', alpha=0.4)\n",
    "ax.set_title(\"k-NN Residuals - MSE = %.1f\" % mse)\n",
    "ax.set_xlabel(\"True Median House Price ($100,000)\")\n",
    "ax.set_ylabel(\"Residual\")\n",
    "ax.hlines(0,min(test_Y),max(test_Y),color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Estimation & Model Selection\n",
    "\n",
    "**Q**: How will our model perform on future data?\n",
    "\n",
    "So far, we’ve split the data, using one set to train the model and the other to test its performance\n",
    "\n",
    "This train-test strategy avoids over-fitting to the sample on hand, but wastes data & can produce poor error estimates.\n",
    "\n",
    "cf. https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "### model selection: cross-validation\n",
    "\n",
    "\n",
    "- *K-fold CV* - randomly split the training data into K \"folds.\"  For each $k=1,...,K$, train model only on the data not in fold $k$ & predict for data in fold $k$.  Compute performance metric over CV predictions.\n",
    "\n",
    "- *Leave-one-out (LOO) CV* -- n-fold CV with  n = number of training points.\n",
    "\n",
    "\n",
    "<img src=\"https://www.evernote.com/l/AUWvg9caKz1OO7opS2Ji3Z7OwOFkLCrg2WsB/image.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/YWgro.gif\" width=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X = housing['data'] ; y = housing['target']\n",
    "\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.LinearRegression()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "def print_cv_score_summary(model, xx, yy, cv, verbose=False):\n",
    "    scores = cross_val_score(model, xx, yy, cv=cv, n_jobs=1, verbose=verbose)\n",
    "    print(\"mean: {:3f}, stdev: {:3f}\".format(\n",
    "        np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the coefficient of determination R^2 of the prediction.\n",
    "print_cv_score_summary(clf, X, y,\n",
    "                       cv=model_selection.KFold(10, shuffle=True, random_state = 42), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cross_val_predict(clf, X, y, \n",
    "                                cv=model_selection.KFold(10, shuffle=True, random_state = 42), n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y, predictions) ; print(mse)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(y, predictions - y,alpha=0.2,edgecolors=None)\n",
    "ax.set_title(\"CV kfold linear model - MSE = %.2f\" % mse)\n",
    "ax.set_xlabel(\"True log normalized Median House Price\")\n",
    "ax.set_ylabel(\"Residual\")\n",
    "ax.hlines(0,min(test_Y),max(test_Y),color=\"red\")\n",
    "ax.set_xlim(0,5.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn = neighbors.KNeighborsRegressor(15)\n",
    "print_cv_score_summary(clf_knn, X, y,\n",
    "                       cv=model_selection.KFold(5, shuffle=True, random_state = 42), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.GridSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"n_neighbors\": [5, 8, 10, 12, 15, 20],  \"weights\": [\"uniform\", \"distance\"]}\n",
    "\n",
    "knn_tune = model_selection.GridSearchCV(clf_knn, parameters, \n",
    "                                        n_jobs = -1, cv = 10, verbose=True, scoring='neg_mean_squared_error')\n",
    "\n",
    "knn_opt = knn_tune.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_opt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astrods",
   "language": "python",
   "name": "astrods"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
